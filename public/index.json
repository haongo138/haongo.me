[{"content":"TLDR;\nSau khi gặp khá nhiều vấn đề với lượng lớn python DAG khi upgrade, viết giúp dag \u0026amp; sau một thời gian thành con rơi, không ai maintain nữa.\nMình tin rằng nhất định có một cách viết dags khác:\n Đơn giản \u0026amp; hiệu quả hơn thế 500 anh em BA, Analytics có thể dễ dàng tự viết pipelines cho riêng mình mà không phải tốn quá nhiều công sức Dễ dàng cho việc monitor, alerting khi có biến xảy ra Upgrade core của airflow không cần phải thay đổi các dags config hiện tại.  Ké vài miếng quảng cáo\n Bạn đang mong muốn tìm kiếm cơ hội mới Bạn muốn làm việc với những công nghệ big data tối tân nhất. Xài serveless tốn kém quá với chậm chạp, bạn có thể tự build \u0026amp; publish cho hơn 500 anh em TIKI xài.  Đến ngay với team data nhé: JD đây nè (Hoặc gửi CV vào mail mình hien.pham2@tiki.vn)\nBối cảnh Bài viết này là cách mình thiết kế \u0026amp; tổ chức config cho airflow (trước thềm đú trend lên cloud).\nNếu bạn đam mê về technical, tham khảo bài viết Path to airflow 2 ở TIKI nhé.\nNhững vấn đề đối với cách viết dags hiện tại:\n Những chuổi ngày copy - paste lăp đi lặp lại (nghe giống DRY - Don\u0026rsquo;t Repeat Your Self Principle không). Nếu không được tổ chức đúng cách, reviews kỹ lưỡng có thể dẫn đến con đường đập đi xây lại một ngày không xa (duplicated and unmaintainable code). Non - tech users (các bạn analytics, BA \u0026hellip;) phải tốn thời gian học python, cách import module như thế nào cho đúng. Điều này dẫn đến một lúc nào đó các chú culi 4.0 (aka data engineer) phải ngồi viết dùm dags cho các em xinh đẹp =)) (Cho chừa tội mê gái) We can do better!  Thế là nông dân quyết tâm thiết kế một cách viết riêng để có thể viết dag một cách ổn định nhất nhất, kể cả khi core của airflow thay đổi (ví dụ import path thay đổi, params thay đổi \u0026hellip;)\nResearch (Lúc này là tháng 09/2019) Mình bắt đầu thử với các keywords: dag config, dag factory, dag yaml, \u0026hellip;\nResearch 1 hồi thì tìm được dag-factory opensource, tương lai đây rồi.\nVới dag-factory thì có 1 số vấn đề mình cần giải quyết:\n users vẫn phải input full cái import path cho operator → Cần pải tạo alias name  Ví dụ airflow.operators.bash_operator.BashOperator → BashOperator   Chỉ cần input những thông tin quan trong.  vd với operator airflow.contrib.operators.bigquery_operator.BigQueryOperator chỉ cần truyền vào: sql , destination_dataset_table. Không cần phải truyền thêm gcp_conn_id, cái option như create_disposition, write_disposition   Tự động phân quyền dags \u0026amp; set connection_id tương ứng cho mỗi team.  vd team 1 thì dùng bigquery_conn_id=team1, dù users có truyền connection_id thì vẫn phải override ở code.   Cần phải force một số conventions:  Mỗi team sẽ có 1 prefix riêng, tiện cho việc phân biệt. Tên file = tên dag → Dễ debug khi có biến.    ⇒ Phải đổi một xíu cái lib dag factory này.\nLet\u0026rsquo;s start ! Với những tinh hoa được học từ thanh niên cứng (SOLID), Open for Extension, Closed For Modification. Giờ không đuợc thay đổi code của dag-factory mà mình sẽ extend nó.\nTức là thay vì vào edit code để support gắn conn_id, operator alias thì mình sẽ tạo thêm 1 layer phía trên và tiến hành convert nó đúng với format mà dag-factory cần.\nBắt đầu với thiết kế alias cho operators\nclass OperatorAlias: # alias name: BigQueryOperator name: str # full module path: airflow.providers.google.cloud.operators.bigquery.BigQueryExecuteQueryOperator module: str # json schema, use for validate the user inputs. # {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;sql\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;minLength\u0026#34;: 2 }}, \u0026#34;required\u0026#34;: [\u0026#34;sql\u0026#34;]} schema: dict # set the default params like connections ... # {\u0026#34;bigquery_conn_id\u0026#34;: \u0026#34;gcp_girls\u0026#34;, \u0026#34;allow_large_results\u0026#34;: true, ...} default_params: dict Với thiết kế 1 alias như trên, bây giờ thay vì phải viết một file python như thế này\nfrom airflow import DAG from airflow.providers.google.cloud.operators.bigquery import BigQueryExecuteQueryOperator from .. import BigQueryTableToOLAPOperator default_args = { \u0026#39;owner\u0026#39;: \u0026#39;my@names.com\u0026#39;, } with DAG( \u0026#39;tutorial\u0026#39;, default_args=default_args, schedule_interval=\u0026#39;0 3 * * *\u0026#39;, tags=[\u0026#39;dwh\u0026#39;,\u0026#39;etl\u0026#39;], ) as dag: t1 = BigQueryExecuteQueryOperator( task_id=\u0026#39;ext_girls\u0026#39;, sql=\u0026#39;SELECT * FROM girls WHERE age \u0026gt;= 18 and age \u0026lt;= 30\u0026#39;, destination_dataset_table=\u0026#39;tiktok_clone.girls_available\u0026#39;, gcp_conn_id=\u0026#39;gcp_girls\u0026#39;, create_disposition=\u0026#34;CREATE_IF_NEEDED\u0026#34;, write_disposition=\u0026#34;WRITE_TRUNCATE\u0026#34;, allow_large_results=True, ) t2 = BigQueryTableToOLAPOperator( task_id=\u0026#39;sync_to_olap\u0026#39;, table=\u0026#39;tiktok_clone.girls_available\u0026#39;, gcp_conn_id=\u0026#39;gcp_girls\u0026#39;, druid_conn_id=\u0026#39;k8s_druid\u0026#39;, date_column=\u0026#39;date\u0026#39;, ) t1 \u0026gt;\u0026gt; t2 Chỉ cần viết 1 file yaml.\n# ext_available_girls.yaml default_args: owner: \u0026#39;my@names.com\u0026#39; schedule_interval: \u0026#39;0 3 * * *\u0026#39; tags: - dwh - etl tasks: ext_girls: operator: BigQueryOperator sql: \u0026#39;SELECT * FROM girls WHERE age \u0026gt;= 18 and age \u0026lt;= 30\u0026#39; destination_dataset_table: tiktok_clone.girls_available sync_to_olap: operator: BigQueryTableToOLAPOperator table: tiktok_clone.girls_available druid_destination_table: girls_available dependencies: - ext_girls Xịn rồi, coi ngày \u0026amp; deploy thôi anh em ơi.\nPhân Quyền PoC (Proof of Concept) cơ bản đã hoạt động được, tiếp theo cần phải giải quyết vấn đề tự động phân quyền \u0026amp; set các connections for mỗi team.\nMỗi team sẽ có 1 role riêng, các DAG sẽ được gắn quyền read trên role này.\nÝ tưởng ban đần là mỗi team sẽ có role riêng, các connection_id, \u0026amp; alert connection_id riêng luôn.\nteams: - name: finances # airflow role_id role_id: 6 # custom alert channel: telegram, slack ... alert: kind: telegram conn_id: fin_alert # force connection_id for a team conns: - conn_id: gcp_team_2 replace_fields: - bigquery_conn_id - gcp_conn_id - google_cloud_storage_conn_id - google_cloud_conn_id Với config như trên thì biết đọc yaml ở folder nào, và thế là mình đã nghĩ ra cách đơn giản là phải bắt buộc các file yaml phải được đặt vào thư mục với name tương ứng. Ví dụ (dags/finances)\nĐến đây chỉ việc viết 1 script python sương sương duyệt folder, parse yaml và:\n Gắn failed_callback tương với alert connection_id. Nếu match replace_fields thì tiến hành thay thế luôn. Về roles: Sau khi nghiên cứu thì mình phát hiện Airflow sử dụng flask-appbuilders, dẫn đến chỉ cần viết 1 câu SQL nhỏ nhỏ để insert quyền read vào bảng ab_permission_view_role với dag_id là đủ xài (Hack nhé, cẩn thận sập =]])  Kết luận WorkFlow  Update SQL, thêm step git commit -m \u0026quot;fix things\u0026quot; git push Pull Request \u0026amp; Merge -\u0026gt; Hệ thống sẽ validate, gắn các alert khi dag failed, tự động retry, \u0026hellip; Done  Ưu điểm  Tiết kiệm thời gian. Với cách viết mới, bây giờ mọi người đều có thể dễ dàng viết pipeline riêng cho mình. Thậm chí có thể viết thêm task ML training, prediction các thứ. Không tốn quá nhiều thời gian để debug, vì nếu dag không đúng format thì đã có alert ngay lập tức. Declarative \u0026amp; Abstraction: Users không cần phải biết quá chi tiết về mỗi operator có những gì, chỉ cần điền những field đủ để run (tất nhiên vẫn cần phải đủ flexible để có thể tùy biến khi cần thiết) Tự động gắn alert khi dag failed. (Mà đối với python phải import tay vào từng DAG). Dễ cho việc upgrade airflow: Bây giờ việc upgrade airflow không còn là ám ảnh.  Nếu airflow đổi import path ⇒ mình chỉ cần tạo đổi module path trong bảng operators là xong. Nếu airflow đổi field name, mình tạo 1 operator adapter và trỏ module path tới operator mình vừa tạo. Life\u0026rsquo;s so easy.   Tự động phân quyền:  Thực tế ở TIKI có khá nhiều team, \u0026amp; mỗi team muốn dag nhà ai nấy ở. Vì vậy mình đã chia mỗi team 1 có 1 folder riêng trong git, hoặc thậm chí là 1 git repo riêng luôn, có role riêng. Mỗi khi gen dag thành công, thì cũng sẽ auto update role tương ứng cho dag đó.    FAQ 1. Tại sao không làm UI cho anh em kéo thả luôn cho tiện ? Cái này hay nè, đợi bạn vào contribute đó (check JD nha)\nThực tế biết về git \u0026amp; version control nói là một điểm mạnh rất lớn cho các bạn analytics, thậm chí cả BA. Vì vậy mình quyết định vẫn giữ git làm nơi lưu giữ các file yaml trên.\n2 ưu điểm lớn của version control:\n Theo dõi được thay đổi từ lúc một file được sinh ra: ai đổi, đổi vì lý do gì. Nếu có biến gì đều có thể quay về phiên bản ổn định nhất. Và sau đó blame người phát =]]. Cho phép nhiều người cùng làm việc chung với nhau trên 1 project, thậm chí là 1 file.  2. 500 anh em xài chung 1 con airflow, có bị kẹt phà giờ cao điểm không chú? Về mặt thiết kế hệ thống, ngay từ đầu mình chọn kubernetes \u0026amp; cài đặt để nó có thể tự động nâng thêm resources \u0026amp;\u0026amp; chọn nodes khác nhau khi có nhiều job chạy (autoscaler). Thực tế mình ghi nhận được có lúc đạt 600 jobs chạy đồng thời.\nThậm chí là chọn được nodes mạnh để run các job tốn nhiều resources:\n Ví dụ training model thì chạy trên con vài chục CPU. Những job đơn giản như chỉ run SQL thì chạy nodes nhỏ hơn.  Những cái này hoàn toàn tự động \u0026amp; anh em không cần phải làm gì thêm.\n(Autoscaling \u0026amp; Distributed đấy =]])\nCần cải tiến. Những thiết kế này chỉ là bước đầu, còn rất nhiều room để cải thiện thêm, 1 case rất điển hình như: Kéo thả dags nì: Thay vì phải ngồi viết yaml, cực nhọc học git, chỉ việc lên UI kéo thả các thứ \u0026amp; Tạo ngay 1 dags cho mình.\nResources Những thiết kế này mình đã hoàn thành vào 2019, nhưng mà idea của nó mình vừa gặp lại 2 ở 2 bài viết khá hay.\n Data Engineers Shouldn\u0026rsquo;t Write Airflow Dags Data Engineers Shouldn\u0026rsquo;t Write Airflow Dags - Part 2  1 phút quảng cáo\n Bạn đang mong muốn tìm kiếm cơ hội mới Bạn muốn làm việc với những công nghệ big data tối tân nhất. Xài serveless tốn kém quá với chậm chạp, bạn có thể tự build \u0026amp; publish cho hơn 500 anh em TIKI xài.  Đến ngay với team data nhé: JD đây nè (Hoặc gửi CV vào mail mình hien.pham2@tiki.vn)\n","permalink":"haongo.me/posts/airflow-dags-the-right-way/","summary":"TLDR;\nSau khi gặp khá nhiều vấn đề với lượng lớn python DAG khi upgrade, viết giúp dag \u0026amp; sau một thời gian thành con rơi, không ai maintain nữa.\nMình tin rằng nhất định có một cách viết dags khác:\n Đơn giản \u0026amp; hiệu quả hơn thế 500 anh em BA, Analytics có thể dễ dàng tự viết pipelines cho riêng mình mà không phải tốn quá nhiều công sức Dễ dàng cho việc monitor, alerting khi có biến xảy ra Upgrade core của airflow không cần phải thay đổi các dags config hiện tại.","title":"Airflow Dags The Right Way"},{"content":"Airflow in the nut shell:\n Một phiên bảo cron tab (chạy mỗi ngày, mỗi tuần, mỗi giờ mỗi tháng) với UI xịn xò. Các tín đồ data hay sử dụng để viết ETL (Extract Transform Load) job  Ví dụ như là select vào rows từ MySQL Thêm ít gia vị (Cooking) Load vào Datawarehouse    Ké vài miếng quảng cáo\n Bạn đang mong muốn tìm kiếm cơ hội mới Bạn muốn làm việc với những công nghệ big data tối tân nhất. Xài serveless tốn kém quá với chậm chạp, bạn có thể tự build \u0026amp; publish cho hơn 500 anh em TIKI xài.  Đến ngay với team data nhé: JD đây nè\nMới vào nghề Team Data Platform của Tiki sử dụng Apache Airflow từ những ngày đầu lập team từ năm 2017. Cho tới hôm nay kiến trúc \u0026amp; cách sử dụng airflow cũng thay đổi khá đáng kể. Bài viết này sẽ chia sẽ cách mà Team Data của dụng airflow, ưu nhược điểm của các cách dùng.\nNgày xửa ngày xưa.\nKhi mình vào TIKI vào T9/2018, một lần được cho vào con airflow chính, một cách ngây thơ updates 1 packages.\n# TLDR: # virtualenv python 2 \u0026amp; airflow 1.8 pip install --upgrade pandas-gbq supervisorctl restart all exit Sau đó tắt máy đi ngủ, tới chiều anh em ping nhau, Airflow ra đi rồi các bác ạ, Rì pọt ra đi hết rồi ông giáo ạ. Nghe xong tè ra quần luôn.\nMistakes:\n Không backup virtualenv trước khi run pip install  Nông dân tập thành cloud 1 năm sau (T9/2019)\nThời điểm này TIKI migrate từ Data Center lên (GCP) Google Cloud Platform. Thế là phải chuẩn bị bưng hệ thống một lần nữa.\nỞ thời điểm này có 3 con airflow đang chạy:\n 1 con chạy jobs ETL (Airflow 1.8) 1 con chạy sync snapshot từ MySQL/Postgres lên BigQuery (Airflow 1.8)  Nghĩ, giờ lên cloud mà xài công nghệ out date thì nông dân quá. Quyết tâm chơi lớn cài airflow latest luôn. DAG thì chắc chỉ cần copy qua là xong, không vỡ gì âu.\nĐược cấp 1 con VM mới trên GCP \u0026amp; ssh vào pip install liền.\nĐang đợi thì tự tát cái bếp. Học Infras As Code các thứ rồi mà lại tay chân thế. Thế là ngồi viết ansible để cài airflow =)). Pip install thì vài phút, ngồi viết mất vài tiếng.\nCopy dag nào thì dags đó vỡ\n Phát hiện ra là import path \u0026amp; params đã thay đổi khá nhiều từ 1.8 lên 1.10. (Lúc này còn ngây thơ mà) Hành ngập mặt rồi, kiểu này migrate chắc tới tết, trong khi anh em lúc đó còn 15 ngày để cutdown.  Ngồi nghĩ nghĩ, mếu được, thế này sau này kiểu gì cũng sẽ gặp case tương tự.\nLúc này sau 1 thời gian được rèn luyện ansible và tập làm văn kubernetes manifests bắt đầu có ý tưởng chế 1 yaml để viết config \u0026amp; build nó thành dag.\nXem bài viết nà\nTLDR:\n Mình viết thêm 1 lớp để set default (giá trị mặc định của các field), tên Operator ngắn gọn xúc tích thay vì phải import 1 path dài ngoằn. Tự động phân quyền cho dag, alert callback vào slack/telegram khi dag failed. Mỗi team có 1 folder riêng trong git hoặc thích thì cho hăn luôn 1 git repo riêng.  Tiếp theo là giờ sẽ deploy ở đâu đây?\nTuy là nông dân nhưng vẫn rất thích đú trend Cờ lâu nây típ (Cloud Native) thế là bắt tay vào nghiên cứu để chạy trên kubernetes luôn.\n CeleryExecutor: có sẵn helm chart airflow để cài. Tuy nhiên lại gặp vấn đề là chúng ta phải tạo trước workers \u0026amp; việc tự động scale cũng không dễ dàng gì. KubernetesExecutor: có thể tự động tạo Pod để run task mà không cần phải tạo worker trước. Nếu executor này kết với với autoscaler \u0026amp; Preemtible Pool của gke thì tuyệt vời ông mặt zời. Chốt nhanh chốt nhanh.  Nghiên cứu vài này thì cũng bắt đầu vào thiết kế \u0026amp; bắt tay vào viết k8s manifest.\nNhững tiêu chí khi deploy airflow trên k8s.\n Phải tiết kiệm: bằng cách tự scale node khi cần (điều này thì autoscalercủa gke đã làm rất tốt. Một cách khác mình nghĩ tới là sử dụng Preemptible VM của GCP: Với loại VM này thì thời gian tối đa của là 24h sau khi được tạo. Google có thể lấy lại (reclaim) bất kì thời điểm nào.  Với những yêu cầu như trên thì mình thiết kế các deployment riêng như sau:\n Scheduler: Core của toàn hệ thống nên phải cực kì stable, nên mình quyết định chọn node standard. (Core chết thì cậu vàng cũng phải bán đi mới mua bánh mì ăn được). Webserver thành 1 deployment riêng (run trên preemtible pool) để tiết kiệm và để HA thì mình tăng ≥ 2 replicas + podAntiAffinity topology là kubernetes.io/hostname. Pod được tạo ra từ airflow scheduler mình set mặc định chạy qua preemtible pool (tiết kiếm tiền để mua bánh mì) \u0026amp; tất nhiên là có hidden option để select node khác khi cần.  Về docker image: Thời điểm này airflow chưa có official image và community docker vẫn còn thiếu nhiều thứ. Mình quyết định viết riêng 1 dockerfile \u0026amp; đưa vào những dependencies cần thiết đủ để airflow chạy được.\nSau khi đủ các nguyên vật liệu thì bắt đầu lên đồ thôi.\nNgoài cách deploy airflow thì còn những bài toán sau cần giải quyết\nCost Saving vs Stable\n Để đảm bảo task chạy ổn định trên Preemtible VM, cần phải bật auto retry cho toàn dag trên hệ thống (việc này cực kì đơn giản nhờ vào config engine).  Lưu file yaml ở đâu?\n Việc sử dụng 1 file config riêng, mình hoàn toàn có thể support một giao diện để viết config hoặc fancy hơn là kéo thả. Nhưng nghĩ đi nghĩ lại thì build 1 UI như vậy khá tốn thời gian \u0026amp; lại phát sinh thêm phải handle conflict khi nhiều người cùng sửa 1 dag. Vì vậy mình đã force mọi người dùng Git. Code yaml sẽ được sync vào deployment Dag Importer, ở đây yaml sẽ được validate \u0026amp; convert thành python DAG file. Sau khi có file DAG, tới vấn đề tiếp theo.  Lưu dag ở đâu?\n Lưu thẳng trong images: có nhược điểm là phải build image liên tục khi có thay đổi → Khó optimize được Pod startup time do phải check Pull Image. Build docker có 1 nhược điểm là khá chậm. Lưu ở Shared Stores: Hiện gại Persistent Disk của gke chưa support Read Write Many , điều này dẫn đến phải sử dụng NFS. IOPS của NFS cực kỳ thấp so với SSD. Việc chọn storage nào phụ thuộc rất nhiều vào kiến trúc của airflow: Sau khi nghiên cứu 1 hồi thì mình nhận thấy là airflow sẽ serialized dag vào database, webserver \u0026amp; các worker đều đọc từ database này.  ⇒ Vì vậy mình chọn shared storages: không ảnh hưởng nhiều tới thời gian chạy task, 1 ưu điểm nữa là nó đơn giản hơn architect của hệ thống.\nLogging như thế nào?\n Khi lên kubernetes option bắt buộc là phải chọn 1 remote logging (cụ thể thì mình chọn gcs để lưu) Nhưng remote logging gặp phải vấn đề là không xem được lúc task đang chạy. Dẫn đến mình phải workaround bằng cách sử dụng 1 file system tạm để lưu logs của task đang chạy. Còn đuờng nào ngoài NFS nữa đâu.  Authentication \u0026amp; Authorization\n Mình định hướng build Airflow trở thành 1 open platform, mọi người đều có thể viết config \u0026amp; chạy. Đối với định hướng như vậy, bắt buộc phải phân quyền thật kỹ \u0026amp; tốt nhất là ở DAG level. Cũng khá may là airflow support Oauth2 \u0026amp; cả access ở DAG level. Việc này trở nên khá đơn giản khi mà config system đã add sẵn DAG vào mỗi role.  Monitor \u0026amp; Alerting\n Với hệ thống config thì mình đã tự động gắn sẵn task_failed_callback. Mỗi team sẽ đuợc tạo 1 connection riêng (có thể là slack/telegram) \u0026amp; lúc failed thì dag nhà ai nấy nhận \u0026amp; tự đi check. Đối với airflow thì mình sử dụng Statsd Exporter để expose metrics API cho prometheus và lên grafana tạo dashboard/alert.  Backfill dags như thế nào?\n Ngày trước cái trên VM thì hay ssh vào server để chạy airflow backfill. Còn trên k8s thì ssh đâu mà vào. Vào pod để execute thì nó lại bị limit ở vài bạn engineer. Vì vậy mình đã custom lại 1 opensource là airflow-backfill-util \u0026amp; share quyền cho mọi người vào backfill.  Vài cảm nhận:\n NFS everywhere. Nói là Preemtible VM nhưng mình cảm nhận là khá là stable, sau 2 năm sử dụng thì mình chưa gặp vấn đề gì quá lớn (Có thể do thiết kế system pro quá nên không bị lỗi :\u0026quot;\u0026gt;)  Lâu lâu có vài task chạy hơn 5h bị down, đối với những task này, mình question ngược lại tại sao nó lại chạy lâu thế →optimize DAG. Đối với Data Scientist Team: Mình white list cho viết hẵn Python code luôn, cho select node xịn để chạy. Chớ model train cũng hết nữa ngày.   Khi chạy airflow trên K8S thì Airflow không còn đơn thuần là chỉ ETL nữa, mà có thể chạy mọi thứ, thanks KubernetesPodOperator.  Hiện tại mình luôn khuyến khích các bạn Data Scientist thay vì viết PythonOperator \u0026amp; nhờ mình cài thêm dependencies vào base image, thì viết một Dockerfile chứ mọi thứ cần thiết ở trong đó (ML Libs, C++ Libs, Code \u0026hellip;) \u0026amp; config KubernetesPodOperator. Việc này vừa đảm bảo tính ổn định, không cần phải add những thứ không cần thiết vào base images sẽ tốn time để pull → giảm startup time.    Airflow 2 Version 2.0 được release vào ngày 2020-12-18 thế nhưng mình chưa dám update ngay, vì trước giờ mỗi lần chỉ update patch version của airflow không què chổ này thì chổ kia. Mà lỗi gặp nhiều nhất vẫn là google oauth2, và phần lớn là do lỗi depedencies 😐.\nSau hơn 8h tháng delay thì quyết tâm làm 1 lần sau cuối.\nLên danh sách những việc cần làm:\n Coi ngày: chọn ngày tốt mới dám upgrade (check xemngay.com) Làm theo upgrade guides: https://airflow.apache.org/docs/apache-airflow/stable/upgrading-to-2.html  Lên airflow 1.10.15 Install backport provider \u0026amp; update module_path vào cái operators (đơn giản là update vào config của operator alias). Generate pod_template_file Run airflow upgrade_check \u0026amp; fix. Đa số lỗi mình gặp đến từ các DAG viết bằng python của team Data Scientist. Không còn cách nào khác là phải đi fix tay từng dag, cũng rất may là khoảng chưa tới 20 dags.    Sau khi lên bridges \u0026amp; chọn đuợc ngày lành tháng tốt. Bắt đầu upgrade airflow 2. Ở tiki thì đa số DAG được chạy vào ban đêm \u0026amp; buổi sáng. Riêng buổi chiều \u0026amp; tối thì rất ít. Thời điểm vàng là đây.\n  Backup Metadata DB: Viết tâm thư gửi anh em system để lỡ mà sự việc không thành, vẫn còn đừong quay về nhà.\n  Scale Down tất cả services: Scheduler, WebServer, ImportDags\n  Merge Pull Request để Build \u0026amp; Deploy.\n  Start 1 replica WebServer, execute bash \u0026amp; run: airflow db upgrade vừa ngồi vừa nghe nhạc để tự trấn an mình =)), chớ lúc đó cũng teo hết mọi thứ rồi.\n  Đợi khoàng 30 phút thì migrate run xong. Mình bắt đầu lên web ui để kiểm tra xem có bị vỡ gì không. Thấy mọi thứ có vẻ ổn.\n  Scale scheduler lên 1 replica. Thấy DAG mếu chạy, bắt đầu xanh cmn mặt.\n Không run được do entrypoint trong docker đã đuợc add sẵn airflow command. Sau đó args lại add thêm airflow nữa.    Sau khi fix lỗi command thì thấy DAG bắt đầu chạy: đi kiểm tra một vòng thì đa số DAG chạy ok, có một số lỗi vặt khá dị:\n env_vars của KubernetesPodOperator tự động nhận diện cái env bắt đầu bằng / thành template file → dẫn đến start pod lỗi. Bug nhọ nhất là admin không được edit user permissions nữa. Phải ngồi đợi bản fix tiếp theo thôi. Logging: Không còn sử dụng connection_id để lấy logging credention cho gcs mà phải mount credential vào pod. Một vài lỗi nhỏ khác do sử dụng internal function của airflow.    Vài cảm nhận về Airflow 2:\n Performance tăng khủng khiếp: Khi số lựợng DAG tăng lên từ vài trăm lên gần 2000, một vấn đề rất lớn gặp phải đối với airflow 1 là thời gian delay giữa các task trong dag rất lớn. Phải mất từ 5 - 15p giữa các task \u0026amp; thời gian start DAG delay khoàng 5 phút so với giờ được set. Khi lên version 2 thì gần như về 0. Điều này cực kỳ có ý nghĩa đối với những task chạy mỗi 1 hoặc 2 phút. UI mới nhìn đẹp hơn hẵn \u0026amp; thực tế là ai cũng khen (chê xấu là disable account nhé). Việc upgrade lần này êm hơn hẵn so với dự tính của mình là có thể không lên được  Vì mình thấy được qua các lần upgrade trước, vỡ rất nhiều chổ    Kết luận Còn chờ đợi gì mà không lên airflow 2 ngay và thôi. Mình đã upgrade thành công bạn cũng thế. Và nhớ coi ngày trước khi upgrade nha.\nỞ trên có quảng cáo rồi, nhưng mình vẫn cứ đăng lại\n Bạn đang mong muốn tìm kiếm cơ hội mới Bạn muốn làm việc với những công nghệ big data tối tân nhất. Xài serveless tốn kém quá với chậm chạp, bạn có thể tự build \u0026amp; publish cho hơn 500 anh em TIKI xài.  Đến ngay với team data nhé: JD đây nè\n","permalink":"haongo.me/posts/apache-airflow/","summary":"Airflow in the nut shell:\n Một phiên bảo cron tab (chạy mỗi ngày, mỗi tuần, mỗi giờ mỗi tháng) với UI xịn xò. Các tín đồ data hay sử dụng để viết ETL (Extract Transform Load) job  Ví dụ như là select vào rows từ MySQL Thêm ít gia vị (Cooking) Load vào Datawarehouse    Ké vài miếng quảng cáo\n Bạn đang mong muốn tìm kiếm cơ hội mới Bạn muốn làm việc với những công nghệ big data tối tân nhất.","title":"Path to airflow 2"}]